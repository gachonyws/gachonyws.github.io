---
title: "하둡(Hadoop) 세부: 하둡 에코시스템 (1/2)"
date: 2020-04-16
header:
  teaser: /assets/images/hadoop.png
  og_image: /assets/images/hadoop.png
categories:
  - hadoop
published: False
---

1. 각 S/W의 개요 및 기능
   * Flume
   * Sqoop
   * Zookeeper
   * Oozie
   * Hbase

   * Pig
   * Hive

---

### Flume

로그 파일, 이메일 메시지, 소셜미디어 데이터와 같이 연속적으로 생성되는 데이터 스트림을 수집 및 전송하고 HDFS에 저장할 수 있는 도구이다.

- 구성 요소
  - 소스(Source): 외부 데이터 소스에 설치되는 에이전트
    - 데이터를 수신한 후 채널로 전달하는 모
    - 하나 이상의 채널로 데이터 전달 가능
    - kafka, http 등 지원되는 소스가 다양

  - 싱크(Sink): 데이터 목적지에 설치되는 에이전트
    - 데이터를 로컬 파일, HDFS, 혹은 다른 flume 에이전트에 전달하는 모듈
    - 하나의 싱크는 오직 한 채널에서만 데이터를 전달받을 수 있
    - HDFS, Hive, IRC 등

  - 채널(Channel): 소스와 싱크 사이의 통로
    - 소스 데이터를 싱크로 전달하는 데이터 큐(Queue)
    - 소스와 싱크의 속도를 조절하는 일종의 버퍼(Buffer)
    - 채널의 데이터는 메모리단에서 저장되고 역할 수행(시스템 장애를 대비해 디스크에 저장 설정 가능)
    - Memory, JDBC, kafka, file 등이 채널의 요소가 될 수 있다.

- 구성 방법
  - 1소스, 1채널, 1싱크(단일)
  - 멀티 에이전트 플로우(단일 에이전트 -> 단일 에이전트)
  - 멀티 에이전트 통합(여러 분산된 에이전트 -> 단일 에이전트가 통합해서 받음)
  - 멀티 플렉싱 플로우 구성(1개의 소스와 여러개의 채널을 사용하여 최종 결과물이 여러가지 다양한 형태로 산출)

---

### 스쿱(Sqoop)

JDBC와 호환되는 RDBMS와 HDFS간의 효율적인 대용량 bulk 데이터 전송 지원 도구이다.(스쿱v1에서는 HDFS뿐만 아니라 Hive 테이블, Hbase 테이블 등 하둡의 다양한 파일 형태로 저장 가능했으나 스쿱v2부터는 미지원 )

![sqoop_img](/assets/images/hadoop_sqoop.png)


**스쿱 설치**

맥 환경에서 brew로 설치하였으나 path 같은 기본적인 설정이 필요

- 터미널 환경에서 path export
```
export SQOOP_VERSION=1.4.7
export SQOOP_HOME=/usr/local/Cellar/sqoop/1.4.7/libexec
export SQOOP_CONF_DIR=$SQOOP_HOME/conf
export SQOOP_LIB_DIR=$SQOOP_HOME/lib
export PATH=$SQOOP_HOME/bin:$PATH
```

- /usr/local/Cellar/sqoop/1.4.7/libexec/conf/sqoop-env.sh 파일 수정
```
export HADOOP_HOME="/usr/local/Cellar/hadoop/3.3.0/libexec"

export HBASE_HOME="/usr/local/Cellar/hbase/2.3.0/libexec"
export HIVE_HOME="/usr/local/Cellar/hive/3.1.2_1/libexec"
export HCAT_HOME="/usr/local/Cellar/hive/3.1.2_1/libexec/hcatalog"
export ZOOCFGDIR="/usr/local/etc/zookeeper"
export ZOOKEEPER_HOME="/usr/local/opt/zookeeper"

```

- Caused by: com.mysql.cj.exceptions.InvalidConnectionAttributeException: The server time zone value 'KST' is unrecognized or represents more than one time zone. 에러 발생. jdbc버전이 높아지면서 생긴 문제라는 거 같아 my.cnf 파일에서 수정

```
# [mysqld] 부분에 추가
default_time_zone='+03:00'
```

---

1. RDBMS 데이터 가져오기

- 데이터 베이스

```
sqoop list-databases --connect jdbc:mysql://<호스트 이름:포트 번호>/
--username <유저ID> --password <패스워드>
...
information_schema
(생략)
```

- 테이블

```
sqoop list-tables --connect jdbc:mysql://<호스트 이름:포트 번호>/<데이터베이스 명>
--username <유저ID> --password <패스워드>
...
(생략)
```

2. 맵 전용 작업을 하둡에 요청

하둡 클러스의 각 노드는 데이터베이스 접근 권한을 미리 부여받아야 함. 자바파일을 먼저 생성 후 동작하는데 이 때 파일을 못찾아서 에러가 나는 경우가 발생한다면 --bindir <스쿱경로/libexec/lib/> 를 추가해야 한다.

```
sqoop import --connect jdbc:mysql://<호스트 이름>/<데이터베이스 명> --username <유저ID> --password <패스워드> --table <테이블 명> -m <맵의 개수 지정> --target-dir <저장할 디렉토리 지정>
```

3. 임포트 후 확인
디렉토리에 저장된 파일은 쉼표로 구분된 필드로 구성된다. hdfs dfs -ls는 디렉토리 내 존재하는 리스트 출력, hdfs cat -ls 는 파일내용 확인.
```
hdfs dfs -ls <디렉토리 경로>
hdfs cat -ls <디렉토리 경로/part-m-00000>
```

4. 익스포트
미리 RDBMS상에 데이터를 저장할 데이터베이스 및 테이블을 생성함.
```
sqoop export --connect jdbc:mysql://<호스트이름>/<DB 명> --username <유저 ID> -password <패스워드> --table <테이블 명> --export-dir <익스포트 할 hdfs의 dfs 경로>
```

임포트나 익스포트 시 --query 'select ~' 옵션을 추가하여 원하는 데이터의 이동만 하는 것도 가능하다. 여러가지 기능상의 이유로 스쿱 버전2보다 버전1을 사용하는 경우도 있다.
{: .notice--info}

---

### Zookeeper

- 코디네이션 서비스 시스템.
  - 분산 환경에서 노드 간에 조정자 역할 수행
  - 노드간 정보 공유, 잠금, 이벤트 등의 기능 수행
  - 여러 개의 노드에 작업을 분산시켜주는 부하 분산 기능 제공
  - 서버에서 처리된 결과를 다른 서버에게 동기화 할 때 잠금(Lock)기능 수행
  - 서버 장애 시 대기 서버가 기존 서버를 대신할 수 있도록 장애상황 판단 및 복구 기능
  - 위의 기능들을 수행하기 위해선 데이터 엑세스가 빨라야 하기 때문에 메모리 상에서 작동

- 구조
  - 디렉토리(=계층=트리) 구조 기반의 데이터 저장소
  - znode라는 데이터 저장 객체를 사용(key,value 방식으로 상태,위치,구성 정보 등으로 구성)

- 노드의 종류
  - Persistent Node: 트랜잭션 로그, 스냅샷, 상태 이미지 등을 저장하고 이름 그대로 명시적으로 삭제하지 않으면 영구적으로 저장
  - Ephemeral Node: 노드를 생성한 클리언트들의 세션이 연결되어 있을 경우에만 유효했다가 연결이 끊어지면 삭제됨
  - Sqequence Node: 노드를 생성할 때 자동으로 일련 번호가 붙는 노드(주로 분산 Lock을 구성할 때 사용)

- Watch 기능: 특정 znode에 watch를 걸어놓고 해당 znode가 변경되었을 때 클라이언트로 callback 호출을 날려줌
- 복제 기능: TCP 연결을 유지하다가 끊어지면 타 서버에 연결

- 활용
  - 클러스터에서 기동중인 서버 목록을 유지
  - 각 서버들의 설정 정보를 저장
  - 글로벌 잠금

cf. 웹 베이스로 관리할 수 있는 Ambari도 존재
{: .notice--info}

---

###  Oozie

여러 아파치 하둡 작업을 실행하고 관리하는 **워크플로우 스케줄러 시스템** 이다. 데이터 수집,처리,분석에 이르는 데이터 파이프 라인을 구성할 시 사용한다.

- 자바 프로그램이나 쉘 스크립트도 하나의 작업으로 만들 수 있다.
- 여러 액션의 DAG(Directed Acycle Graph)로 표현

- 워크플로우: 제어 종속성을 가짐(선행작업이 완료되지 않으면 다음 작업을 할 수 가 없음)
  - 시작/종료 노드
  - 실패 노드
  - 액션 노드(실제로 태스크를 정의)
  - 포크(동시에 작업을 여러개 수행하도록 워크 플로우를 분기)/조인 노드(분기된 노드들이 합쳐지게 함)
  - 제어 판단 노드(switch-case와 비슷하게 조건을 주어서 제어)
- 코디네이터: 예약된 워크플로우 작업
- 번들: 여러 코디네이터를 모아놓은 것

- 예시(word-count 맵리듀스 작업 실행)
작업을 수행 -> 정상 종료 or 비정상 종료

---

### HBase

구글 Big Table이후에 모델링된 오픈소스로 하둡을 기반으로 컬럼 베이스로 구성된 스키마 없는 데이터베이스.

- 개요
  - 조인, 인덱스가 없음
  - 비정형/반정형 대량 데이터를 저장할 때 많이 사용
  - 테이블은 N개의 컬럼을 가질 수 있다.(1개의 rowkey(유일하게 인덱스처럼 쓰임), 여러개의 컬럼패밀리)

- 데이터 관리 방법
  - create: 데이터베이스 생성
  - put: 데이터 입력
  - get: 데이터 읽기
  - scan: 테이블의 여러 행에서 데이터를 가져옴

![ecosystem_img](/assets/images/hadoop_hbase.png)


- 설치
```
brew install hbase
```
- 설정
1. /usr/local/Cellar/hbase/{version}/libexec/conf 으로 이동
2. hbase-site.xml을 열어서 수정.
3. 설정을 추가.
```
<!-- add quorum to localhost-->
<property>
	<name>hbase.zookeeper.quorum</name>
	<value>localhost</value>
</property>
<!-- add znode parent config -->
<property>
	<name>zookeeper.znode.parent</name>
	<value>/hbase-unsecure</value>
</property>
```

1. quorum은 Hbase의 클러스터 설정입니다. 이곳에 클러스터로 사용할 node의 주소를 입력. ()로컬에서 stand alone으로 띄울 것이기 때문에, localhost 주소를 입력)
2. 바로 위에서 살펴보았듯 zookeeper는 znode라는 데이터 저장 객체를 가지고 있습니다. 이 설정은 Hbase에서 사용할 Root Znode를 가리키는 설정입니다. hbase-unsecure로 세팅해줍니다.

- hbase master 실행
```
hbase master start
```

- hbase 실행
```
hbase shell
```  

- 테이블 생성
```
create 'contacts','personal','office'
```

- 테이블 확인
```
list
```

- 데이터 입력
```
put 'contacts','1000','personal:name','dooli'
put 'contacts','1000','personal:phone','010-0000-0001'
put 'contacts','1000','office:name','michael'
put 'contacts','1000','office:phone','010-0000-0002'
```

- 데이터 확인
```
scan 'contacts'


hbase(main):017:0> scan 'contacts'
ROW                   COLUMN+CELL
 1000                 column=office:name, timestamp=2020-08-13T09:15:01.481Z, va
                      lue=michael
 1000                 column=office:phone, timestamp=2020-08-13T09:15:15.822Z, v
                      alue=010-0000-0002
 1000                 column=personal:name, timestamp=2020-08-13T09:13:50.036Z,
                      value=dooli
 1000                 column=personal:phone, timestamp=2020-08-13T09:14:30.926Z,
                       value=010-0000-0001
1 row(s)
Took 0.0290 seconds
```

---

### Pig


---

### Hive

SQL과 유사한 HiveQL

---
